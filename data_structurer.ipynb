{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reformatter and resampler of APPA's data\n",
    "mainly by *Samuele Facenda*\n",
    "\n",
    "copy-paste contributed by *Magoni Parker*\n",
    "\n",
    "\n",
    "--- \n",
    "\n",
    "convert the table with a column for every channel to a table(with a table with the chenges of sensing materials) with a feature that is the sensing material, age of the sensor, sin and cos of date and a lot of other things\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import locale\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import math\n",
    "from numpy import NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elaborate_file(file_name, sensing_material_table_file):\n",
    "    sensing_table = pd.read_csv(sensing_material_table_file)\n",
    "    raw_table = pd.read_csv(file_name)\n",
    "    # todo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read the files ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensing_table = pd.read_csv(\"../sensing_material_appa1.csv\")\n",
    "raw_table = pd.read_csv(\"../appa1.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the name of the column in the transform file is a string, i must have a list with this strings and a list with the convertion in timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the timestamp of the sensing material change date\n",
    "dates_str = sensing_table.columns.to_list()\n",
    "dates_str.remove(\"nm\")\n",
    "dates = [pd.to_datetime(x) for x in dates_str]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### refactor:\n",
    "convert in timestamp and aggregate every hour with the mean, also remove strange nulnulnulnulnulnul rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_table = raw_table[raw_table.ts.str.contains(\"\\0\") == False]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change raw_table ts column to timestamp\n",
    "raw_table.ts = pd.to_datetime(raw_table.ts.str.slice(start = 0, stop = 24), format = \"%a %b %d %Y %H:%M:%S\")\n",
    "NUMBER_OF_SENSORS = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set and reset index to computate the mea\n",
    "raw_table = raw_table.set_index(\"ts\")\n",
    "raw_table = raw_table.resample(\"H\").mean()\n",
    "raw_table = raw_table.reset_index(level=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### utility functions:\n",
    "get_sensing_mat:\n",
    "- index_date is the number of column in the tranform file where to search\n",
    "- channel is the channel to get\n",
    "\n",
    "find_change_date:\n",
    "- the index is the column of the file where to search in the channel\n",
    "- channel is the channel\n",
    "\n",
    "a little recursive function, if there is a * in the name recall himself with a lower index, if the lower index is a different molecule, check in the other channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sensing_mat(index_date, channel):\n",
    "    return sensing_table[dates_str[index_date]][sensing_table.nm == channel].values[0]\n",
    "\n",
    "def find_change_date(index_date_reach, channel):\n",
    "    actual_sens_mat = get_sensing_mat(index_date_reach, channel)\n",
    "    if  not '*' in actual_sens_mat:\n",
    "        return dates[index_date_reach]\n",
    "    else:\n",
    "        # find the last change\n",
    "        if get_sensing_mat(index_date_reach -1,channel) in actual_sens_mat:\n",
    "            # do the same thing on the previus cell\n",
    "            return find_change_date(index_date_reach - 1, channel)\n",
    "        else:\n",
    "            # the sensor changed channel, find the channel and do the same thing\n",
    "            channel_before = 1\n",
    "            while channel_before <= NUMBER_OF_SENSORS:\n",
    "                if get_sensing_mat(index_date_reach -1,channel_before) in actual_sens_mat:\n",
    "                    break\n",
    "                channel_before += 1\n",
    "            else:\n",
    "                raise Exception(f\"error in find previus position of sensor\\n actual index {index_date_reach} type {actual_sens_mat}\")\n",
    "            return find_change_date(index_date_reach - 1, channel_before)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define the columns\n",
    "\n",
    "create a new dataframe, the structure is too different, I can't keep the old one\n",
    "\n",
    "keep track during the iteration of the material in every channel and the timestamp of his first installation\n",
    "\n",
    "in the iteration(on every row, called record) check if the date is before the first certified installation(if so skip to the next row), check if a sensing material change day is reached(and then computate and update the traks array ex. lasta_change_data...), so for every channel create a row with all the columns and fill it. \n",
    "\n",
    "In the end of every iteration concatenate the temporary dataset to the final one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "columns = ['ts','sensing_material','signal_res','heater_res','heater_V','T','RH','P','sin_hour','cos_hour','sin_ordate','cos_ordate','sin_weekday','cos_weekday','year','age']\n",
    "new_data = pd.DataFrame(columns=columns)\n",
    "\n",
    "last_change_date = [dates[0] for _ in range(NUMBER_OF_SENSORS)]\n",
    "index_date_reached = 0\n",
    "actual_sensing_material = [get_sensing_mat(0, i) for i in range(1, NUMBER_OF_SENSORS + 1)]\n",
    "\n",
    "for index, record in tqdm(raw_table.iterrows(), total = raw_table.shape[0]):\n",
    "    if record.ts.date() < dates[0].date():\n",
    "        # skip all data before sensor changing(and sensing mat knowing)\n",
    "        continue\n",
    "\n",
    "    if index_date_reached != len(dates) and record.ts.date() == dates[index_date_reached+1].date():\n",
    "        # reached sensing material change day\n",
    "        index_date_reached += 1\n",
    "        for channel in range(NUMBER_OF_SENSORS):\n",
    "            last_change_date[channel] = find_change_date(index_date_reached, channel+1)\n",
    "\n",
    "        # update the sensing material array\n",
    "        actual_sensing_material = [get_sensing_mat(index_date_reached,i) for i in range(1, NUMBER_OF_SENSORS + 1)]\n",
    "\n",
    "    append_ds = pd.DataFrame(columns=columns)\n",
    "    for channel in range(1, NUMBER_OF_SENSORS + 1):\n",
    "        if pd.isnull(record[\"Rs\" + str(channel)]):\n",
    "            continue\n",
    "        # for every channel add a row\n",
    "        append_ds.loc[len(append_ds.index)] = [\n",
    "            record['ts'],\n",
    "            actual_sensing_material[channel - 1].replace(\"*\",\"\"),\n",
    "            record['Rs' + str(channel)],\n",
    "            record['Rh' + str(channel)],\n",
    "            record['Vh' + str(channel)],\n",
    "            record['T'],\n",
    "            record['RH'],\n",
    "            record['P'],\n",
    "            math.sin(record['ts'].hour) * 2 * (math.pi / 24),\n",
    "            math.cos(record['ts'].hour) * 2 * (math.pi / 24),\n",
    "            math.sin(record['ts'].toordinal()) * 2 * (math.pi / 366),\n",
    "            math.cos(record['ts'].toordinal()) * 2 * (math.pi / 366),\n",
    "            math.sin(record['ts'].weekday()) * 2 * (math.pi / 7),\n",
    "            math.cos(record['ts'].weekday()) * 2 * (math.pi / 7),\n",
    "            record['ts'].year,\n",
    "            (record['ts'] - last_change_date[channel - 1]).days\n",
    "        ]\n",
    "        \n",
    "    new_data = pd.concat(objs=(new_data, append_ds))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last clear and file/print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = new_data.dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(new_data)\n",
    "new_data.to_csv(\"../appa1_new.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
