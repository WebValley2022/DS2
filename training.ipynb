{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import time\n",
    "import math\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "from matplotlib import pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')\n",
    "\n",
    "appa1 = pd.read_csv(\"noam_exports/appa1.csv\")\n",
    "appa1 = appa1.drop(columns='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN-LSTM Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN_LSTM(\n",
      "  (conv): Conv2d(1, 40, kernel_size=(4, 37), stride=(1, 1))\n",
      "  (maxpool): MaxPool2d(kernel_size=(4, 37), stride=(4, 37), padding=0, dilation=1, ceil_mode=False)\n",
      "  (lstm): LSTM(15, 200)\n",
      "  (fc1): Linear(in_features=200, out_features=150, bias=True)\n",
      "  (fc2): Linear(in_features=150, out_features=50, bias=True)\n",
      "  (fc3): Linear(in_features=50, out_features=3, bias=True)\n",
      "  (dropout1): Dropout(p=0.03, inplace=False)\n",
      "  (dropout2): Dropout(p=0.1, inplace=False)\n",
      "  (dropout3): Dropout(p=0.1, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torch import max_pool2d\n",
    "\n",
    "\n",
    "class CNN_LSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_LSTM, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels=1, out_channels=40, kernel_size=(4, 37))\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=(4, 37))\n",
    "        self.lstm = nn.LSTM(15, 200)\n",
    "        self.fc1 = nn.Linear(200, 150)\n",
    "        self.fc2 = nn.Linear(150, 50)\n",
    "        self.fc3 = nn.Linear(50,3)\n",
    "        self.dropout1 = nn.Dropout(0.03)\n",
    "        self.dropout2 = nn.Dropout(0.1)\n",
    "        self.dropout3 = nn.Dropout(0.1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = F.relu(x)\n",
    "        x = torch.squeeze(x)\n",
    "        print(x.shape)\n",
    "        print(x.size(-1))\n",
    "        x, (h_n, c_n) = self.lstm(x, (torch.zeros(2, 15, 200), torch.zeros(2, 15, 200)))\n",
    "        x = F.relu(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.dropout3(x)\n",
    "        return x\n",
    "\n",
    "CNN_LSTM = CNN_LSTM()\n",
    "print(CNN_LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = appa1[[\n",
    "       'ZnOR_1', 'ZnOR_2',\n",
    "       'LaFeO3_1', 'LaFeO3_2',\n",
    "       'WO3_1', 'WO3_2',\n",
    "       'ZnOR_1_heatR', 'ZnOR_2_heatR',\n",
    "       'LaFeO3_1_heatR', 'LaFeO3_2_heatR',\n",
    "       'WO3_1_heatR', 'WO3_2_heatR',\n",
    "       'ZnOR_1_heatV', 'ZnOR_2_heatV',\n",
    "       'LaFeO3_1_heatV', 'LaFeO3_2_heatV',\n",
    "       'WO3_1_heatV', 'WO3_2_heatV',\n",
    "       'Temperature', 'Relative_Humidity', 'Pressure', 'VOC',\n",
    "       'ZnOR_1_Age', 'ZnOR_2_Age',\n",
    "       'LaFeO3_1_Age', 'LaFeO3_2_Age',\n",
    "       'WO3_1_Age', 'WO3_2_Age',\n",
    "       'sin_hour', 'cos_hour',\n",
    "       'sin_weekday', 'cos_weekday',\n",
    "       'sin_month', 'cos_month',\n",
    "       'sin_ordate', 'cos_ordate',\n",
    "       'year'\n",
    "    ]].to_numpy()\n",
    "Y = appa1[['NO2', 'O3', 'CO']].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((13678, 1, 24, 37), (13678, 3))"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.lib.stride_tricks.sliding_window_view(X, (24,37))\n",
    "Y = Y[X.shape[2]-1:]\n",
    "(X.shape,Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(list(zip(X,Y)), test_size=0.2)\n",
    "\n",
    "train_dl = DataLoader(train, batch_size=15, shuffle=True)\n",
    "test_dl = DataLoader(test, batch_size=15, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(model):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = CNN_LSTM\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "    for epoch in range(1, 11):\n",
    "        train_loss = 0\n",
    "        for features, tag in tqdm(train_dl):\n",
    "            optimizer.zero_grad()\n",
    "            pred = model(torch.tensor(features).float())\n",
    "            loss = criterion(pred, tag)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        print(f'EPOCH: {epoch}; TRAIN LOSS: {train_loss}')\n",
    "        test_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for features, tag in tqdm(test_dl):\n",
    "                pred = model(tag)\n",
    "                loss = criterion(pred, tag)\n",
    "                test_loss += loss.item()\n",
    "                print(f'EPOCH: {epoch}; TEST LOSS: {test_loss}')\n",
    "\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/730 [00:00<?, ?it/s]C:\\Users\\nzams\\AppData\\Local\\Temp\\ipykernel_12912\\1177280461.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pred = model(torch.tensor(features).float())\n",
      "  0%|          | 0/730 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given input size: (40x21x1). Calculated output size: (40x5x0). Output size is too small",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\nzams\\Desktop\\DS2\\training.ipynb Cell 9\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/nzams/Desktop/DS2/training.ipynb#ch0000016?line=0'>1</a>\u001b[0m fit_model(CNN_LSTM)\n",
      "\u001b[1;32mc:\\Users\\nzams\\Desktop\\DS2\\training.ipynb Cell 9\u001b[0m in \u001b[0;36mfit_model\u001b[1;34m(model)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nzams/Desktop/DS2/training.ipynb#ch0000016?line=7'>8</a>\u001b[0m \u001b[39mfor\u001b[39;00m features, tag \u001b[39min\u001b[39;00m tqdm(train_dl):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nzams/Desktop/DS2/training.ipynb#ch0000016?line=8'>9</a>\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/nzams/Desktop/DS2/training.ipynb#ch0000016?line=9'>10</a>\u001b[0m     pred \u001b[39m=\u001b[39m model(torch\u001b[39m.\u001b[39;49mtensor(features)\u001b[39m.\u001b[39;49mfloat())\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nzams/Desktop/DS2/training.ipynb#ch0000016?line=10'>11</a>\u001b[0m     loss \u001b[39m=\u001b[39m criterion(pred, tag)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nzams/Desktop/DS2/training.ipynb#ch0000016?line=11'>12</a>\u001b[0m     loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32mc:\\Users\\nzams\\Desktop\\DS2\\training.ipynb Cell 9\u001b[0m in \u001b[0;36mCNN_LSTM.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nzams/Desktop/DS2/training.ipynb#ch0000016?line=16'>17</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nzams/Desktop/DS2/training.ipynb#ch0000016?line=17'>18</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv(x)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/nzams/Desktop/DS2/training.ipynb#ch0000016?line=18'>19</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmaxpool(x)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nzams/Desktop/DS2/training.ipynb#ch0000016?line=19'>20</a>\u001b[0m     x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(x)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nzams/Desktop/DS2/training.ipynb#ch0000016?line=20'>21</a>\u001b[0m     x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msqueeze(x)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\pooling.py:162\u001b[0m, in \u001b[0;36mMaxPool2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor):\n\u001b[1;32m--> 162\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mmax_pool2d(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkernel_size, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[0;32m    163\u001b[0m                         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, ceil_mode\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mceil_mode,\n\u001b[0;32m    164\u001b[0m                         return_indices\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreturn_indices)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\_jit_internal.py:423\u001b[0m, in \u001b[0;36mboolean_dispatch.<locals>.fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    421\u001b[0m     \u001b[39mreturn\u001b[39;00m if_true(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    422\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 423\u001b[0m     \u001b[39mreturn\u001b[39;00m if_false(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\functional.py:782\u001b[0m, in \u001b[0;36m_max_pool2d\u001b[1;34m(input, kernel_size, stride, padding, dilation, ceil_mode, return_indices)\u001b[0m\n\u001b[0;32m    780\u001b[0m \u001b[39mif\u001b[39;00m stride \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    781\u001b[0m     stride \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mjit\u001b[39m.\u001b[39mannotate(List[\u001b[39mint\u001b[39m], [])\n\u001b[1;32m--> 782\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mmax_pool2d(\u001b[39minput\u001b[39;49m, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Given input size: (40x21x1). Calculated output size: (40x5x0). Output size is too small"
     ]
    }
   ],
   "source": [
    "fit_model(CNN_LSTM)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
