{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import time\n",
    "import math\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "from matplotlib import pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')\n",
    "\n",
    "appa1 = pd.read_csv(\"noam_exports/appa1.csv\")\n",
    "appa1 = appa1.drop(columns='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN-LSTM Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNNLSTM(\n",
      "  (conv): Conv2d(1, 40, kernel_size=(4, 37), stride=(1, 1))\n",
      "  (lstm): LSTM(15, 200)\n",
      "  (fc1): Linear(in_features=200, out_features=150, bias=True)\n",
      "  (fc2): Linear(in_features=150, out_features=50, bias=True)\n",
      "  (fc3): Linear(in_features=50, out_features=3, bias=True)\n",
      "  (dropout1): Dropout(p=0.03, inplace=False)\n",
      "  (dropout2): Dropout(p=0.1, inplace=False)\n",
      "  (dropout3): Dropout(p=0.1, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class CNN_LSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_LSTM, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels=1, out_channels=40, kernel_size=(4, 37))\n",
    "        self.lstm = nn.LSTM(15, 200)\n",
    "        self.fc1 = nn.Linear(200, 150)\n",
    "        self.fc2 = nn.Linear(150, 50)\n",
    "        self.fc3 = nn.Linear(50,3)\n",
    "        self.dropout1 = nn.Dropout(0.03)\n",
    "        self.dropout2 = nn.Dropout(0.1)\n",
    "        self.dropout3 = nn.Dropout(0.1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = F.relu(x)\n",
    "        x = torch.flatten(x)\n",
    "        print(x.shape)\n",
    "        x, (h_n, c_n) = self.lstm(x, (torch.zeros(2, 15, 200), torch.zeros(2, 15, 200)))\n",
    "        x = F.relu(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.dropout3(x)\n",
    "        return x\n",
    "\n",
    "CNN_LSTM = CNNLSTM()\n",
    "print(CNN_LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = appa1[[\n",
    "       'ZnOR_1', 'ZnOR_2',\n",
    "       'LaFeO3_1', 'LaFeO3_2',\n",
    "       'WO3_1', 'WO3_2',\n",
    "       'ZnOR_1_heatR', 'ZnOR_2_heatR',\n",
    "       'LaFeO3_1_heatR', 'LaFeO3_2_heatR',\n",
    "       'WO3_1_heatR', 'WO3_2_heatR',\n",
    "       'ZnOR_1_heatV', 'ZnOR_2_heatV',\n",
    "       'LaFeO3_1_heatV', 'LaFeO3_2_heatV',\n",
    "       'WO3_1_heatV', 'WO3_2_heatV',\n",
    "       'Temperature', 'Relative_Humidity', 'Pressure', 'VOC',\n",
    "       'ZnOR_1_Age', 'ZnOR_2_Age',\n",
    "       'LaFeO3_1_Age', 'LaFeO3_2_Age',\n",
    "       'WO3_1_Age', 'WO3_2_Age',\n",
    "       'sin_hour', 'cos_hour',\n",
    "       'sin_weekday', 'cos_weekday',\n",
    "       'sin_month', 'cos_month',\n",
    "       'sin_ordate', 'cos_ordate',\n",
    "       'year'\n",
    "    ]].to_numpy()\n",
    "Y = appa1[['NO2', 'O3', 'CO']].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((13678, 1, 24, 37), (13678, 3))"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.lib.stride_tricks.sliding_window_view(X, (24,37))\n",
    "Y = Y[X.shape[2]-1:]\n",
    "(X.shape,Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(list(zip(X,Y)), test_size=0.2)\n",
    "\n",
    "train_dl = DataLoader(train, batch_size=15, shuffle=True)\n",
    "test_dl = DataLoader(test, batch_size=15, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(model):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = CNN_LSTM\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "    for epoch in range(1, 11):\n",
    "        train_loss = 0\n",
    "        for features, tag in tqdm(train_dl):\n",
    "            optimizer.zero_grad()\n",
    "            pred = model(torch.tensor(features).float())\n",
    "            loss = criterion(pred, tag)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        print(f'EPOCH: {epoch}; TRAIN LOSS: {train_loss}')\n",
    "        test_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for features, tag in tqdm(test_dl):\n",
    "                pred = model(tag)\n",
    "                loss = criterion(pred, tag)\n",
    "                test_loss += loss.item()\n",
    "                print(f'EPOCH: {epoch}; TEST LOSS: {test_loss}')\n",
    "\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/730 [00:00<?, ?it/s]C:\\Users\\nzams\\AppData\\Local\\Temp\\ipykernel_12912\\1177280461.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pred = model(torch.tensor(features).float())\n",
      "  0%|          | 0/730 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12600])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "For unbatched 2-D input, hx and cx should also be 2-D but got (3-D, 3-D) tensors",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\nzams\\Desktop\\DS2\\training.ipynb Cell 9\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/nzams/Desktop/DS2/training.ipynb#ch0000016?line=0'>1</a>\u001b[0m fit_model(CNN_LSTM)\n",
      "\u001b[1;32mc:\\Users\\nzams\\Desktop\\DS2\\training.ipynb Cell 9\u001b[0m in \u001b[0;36mfit_model\u001b[1;34m(model)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nzams/Desktop/DS2/training.ipynb#ch0000016?line=7'>8</a>\u001b[0m \u001b[39mfor\u001b[39;00m features, tag \u001b[39min\u001b[39;00m tqdm(train_dl):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nzams/Desktop/DS2/training.ipynb#ch0000016?line=8'>9</a>\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/nzams/Desktop/DS2/training.ipynb#ch0000016?line=9'>10</a>\u001b[0m     pred \u001b[39m=\u001b[39m model(torch\u001b[39m.\u001b[39;49mtensor(features)\u001b[39m.\u001b[39;49mfloat())\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nzams/Desktop/DS2/training.ipynb#ch0000016?line=10'>11</a>\u001b[0m     loss \u001b[39m=\u001b[39m criterion(pred, tag)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nzams/Desktop/DS2/training.ipynb#ch0000016?line=11'>12</a>\u001b[0m     loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32mc:\\Users\\nzams\\Desktop\\DS2\\training.ipynb Cell 9\u001b[0m in \u001b[0;36mCNNLSTM.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nzams/Desktop/DS2/training.ipynb#ch0000016?line=15'>16</a>\u001b[0m x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mflatten(x)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nzams/Desktop/DS2/training.ipynb#ch0000016?line=16'>17</a>\u001b[0m \u001b[39mprint\u001b[39m(x\u001b[39m.\u001b[39mshape)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/nzams/Desktop/DS2/training.ipynb#ch0000016?line=17'>18</a>\u001b[0m x, (h_n, c_n) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlstm(x, (torch\u001b[39m.\u001b[39;49mzeros(\u001b[39m2\u001b[39;49m, \u001b[39m15\u001b[39;49m, \u001b[39m200\u001b[39;49m), torch\u001b[39m.\u001b[39;49mzeros(\u001b[39m2\u001b[39;49m, \u001b[39m15\u001b[39;49m, \u001b[39m200\u001b[39;49m)))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nzams/Desktop/DS2/training.ipynb#ch0000016?line=18'>19</a>\u001b[0m x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(x)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nzams/Desktop/DS2/training.ipynb#ch0000016?line=19'>20</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc1(x)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\rnn.py:760\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    757\u001b[0m         \u001b[39mif\u001b[39;00m hx[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mdim() \u001b[39m!=\u001b[39m \u001b[39m2\u001b[39m \u001b[39mor\u001b[39;00m hx[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mdim() \u001b[39m!=\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[0;32m    758\u001b[0m             msg \u001b[39m=\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39mFor unbatched 2-D input, hx and cx should \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    759\u001b[0m                    \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39malso be 2-D but got (\u001b[39m\u001b[39m{\u001b[39;00mhx[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mdim()\u001b[39m}\u001b[39;00m\u001b[39m-D, \u001b[39m\u001b[39m{\u001b[39;00mhx[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mdim()\u001b[39m}\u001b[39;00m\u001b[39m-D) tensors\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 760\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(msg)\n\u001b[0;32m    761\u001b[0m         hx \u001b[39m=\u001b[39m (hx[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39munsqueeze(\u001b[39m1\u001b[39m), hx[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39munsqueeze(\u001b[39m1\u001b[39m))\n\u001b[0;32m    763\u001b[0m \u001b[39m# Each batch of the hidden state should match the input sequence that\u001b[39;00m\n\u001b[0;32m    764\u001b[0m \u001b[39m# the user believes he/she is passing in.\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: For unbatched 2-D input, hx and cx should also be 2-D but got (3-D, 3-D) tensors"
     ]
    }
   ],
   "source": [
    "fit_model(CNN_LSTM)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
