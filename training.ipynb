{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import time\n",
    "import math\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "from matplotlib import pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')\n",
    "\n",
    "appa1 = pd.read_csv(\"noam_exports/appa1.csv\")\n",
    "appa1 = appa1.drop(columns='Unnamed: 0')\n",
    "\n",
    "appa2 = pd.read_csv(\"noam_exports/appa1.csv\")\n",
    "appa2 = appa2.drop(columns='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN-LSTM Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN_LSTM(\n",
      "  (conv1): Conv2d(1, 40, kernel_size=(4, 37), stride=(1, 1))\n",
      "  (lstm): LSTM(21, 200)\n",
      "  (conv2): Conv2d(15, 5, kernel_size=(40, 200), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=5, out_features=150, bias=True)\n",
      "  (fc2): Linear(in_features=150, out_features=50, bias=True)\n",
      "  (fc3): Linear(in_features=50, out_features=3, bias=True)\n",
      "  (dropout1): Dropout(p=0.03, inplace=False)\n",
      "  (dropout2): Dropout(p=0.1, inplace=False)\n",
      "  (dropout3): Dropout(p=0.1, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torch import max_pool2d\n",
    "\n",
    "\n",
    "class CNN_LSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_LSTM, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=40, kernel_size=(4, 37))\n",
    "        self.lstm = nn.LSTM(21, 200)\n",
    "        self.conv2 = nn.Conv2d(in_channels=15, out_channels=5, kernel_size=(40, 200))\n",
    "        self.fc1 = nn.Linear(5, 150)\n",
    "        self.fc2 = nn.Linear(150, 50)\n",
    "        self.fc3 = nn.Linear(50, 3)\n",
    "        self.dropout1 = nn.Dropout(0.03)\n",
    "        self.dropout2 = nn.Dropout(0.1)\n",
    "        self.dropout3 = nn.Dropout(0.1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = torch.squeeze(x)\n",
    "        x, (h_n, c_n) = self.lstm(x, (torch.zeros(1, 40, 200), torch.zeros(1, 40, 200)))\n",
    "        x = self.conv2(x)\n",
    "        x = torch.flatten(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.dropout3(x)\n",
    "        return x\n",
    "\n",
    "CNN_LSTM = CNN_LSTM()\n",
    "print(CNN_LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = appa1[[\n",
    "       'ZnOR_1', 'ZnOR_2',\n",
    "       'LaFeO3_1', 'LaFeO3_2',\n",
    "       'WO3_1', 'WO3_2',\n",
    "       'ZnOR_1_heatR', 'ZnOR_2_heatR',\n",
    "       'LaFeO3_1_heatR', 'LaFeO3_2_heatR',\n",
    "       'WO3_1_heatR', 'WO3_2_heatR',\n",
    "       'ZnOR_1_heatV', 'ZnOR_2_heatV',\n",
    "       'LaFeO3_1_heatV', 'LaFeO3_2_heatV',\n",
    "       'WO3_1_heatV', 'WO3_2_heatV',\n",
    "       'Temperature', 'Relative_Humidity', 'Pressure', 'VOC',\n",
    "       'ZnOR_1_Age', 'ZnOR_2_Age',\n",
    "       'LaFeO3_1_Age', 'LaFeO3_2_Age',\n",
    "       'WO3_1_Age', 'WO3_2_Age',\n",
    "       'sin_hour', 'cos_hour',\n",
    "       'sin_weekday', 'cos_weekday',\n",
    "       'sin_month', 'cos_month',\n",
    "       'sin_ordate', 'cos_ordate',\n",
    "       'year'\n",
    "    ]].to_numpy()\n",
    "Y = appa1[['NO2', 'O3', 'CO']].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((13678, 1, 24, 37), (13678, 3))"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.lib.stride_tricks.sliding_window_view(X, (24, 37))\n",
    "Y = Y[X.shape[2] - 1 :]\n",
    "(X.shape, Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(list(zip(X,Y)), test_size=0.2)\n",
    "\n",
    "train_dl = DataLoader(train, batch_size=15, shuffle=True)\n",
    "test_dl = DataLoader(test, batch_size=15, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(model):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = CNN_LSTM\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "    for epoch in range(1, 11):\n",
    "        train_loss = 0\n",
    "        for features, tag in tqdm(train_dl):\n",
    "            tag = tag.float()\n",
    "            optimizer.zero_grad()\n",
    "            pred = model(features.clone().detach().float())\n",
    "            loss = criterion(pred, tag)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        print(f'EPOCH: {epoch}; TRAIN LOSS: {train_loss}')\n",
    "        test_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for features, tag in tqdm(test_dl):\n",
    "                pred = model(tag)\n",
    "                loss = criterion(pred, tag)\n",
    "                test_loss += loss.item()\n",
    "                print(f'EPOCH: {epoch}; TEST LOSS: {test_loss}')\n",
    "\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 729/730 [00:27<00:00, 26.21it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [5, 15, 40, 200], expected input[1, 7, 40, 200] to have 15 channels, but got 7 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\nzams\\Desktop\\DS2\\training.ipynb Cell 9\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/nzams/Desktop/DS2/training.ipynb#ch0000016?line=0'>1</a>\u001b[0m fit_model(CNN_LSTM)\n",
      "\u001b[1;32mc:\\Users\\nzams\\Desktop\\DS2\\training.ipynb Cell 9\u001b[0m in \u001b[0;36mfit_model\u001b[1;34m(model)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nzams/Desktop/DS2/training.ipynb#ch0000016?line=8'>9</a>\u001b[0m tag \u001b[39m=\u001b[39m tag\u001b[39m.\u001b[39mfloat()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nzams/Desktop/DS2/training.ipynb#ch0000016?line=9'>10</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/nzams/Desktop/DS2/training.ipynb#ch0000016?line=10'>11</a>\u001b[0m pred \u001b[39m=\u001b[39m model(features\u001b[39m.\u001b[39;49mclone()\u001b[39m.\u001b[39;49mdetach()\u001b[39m.\u001b[39;49mfloat())\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nzams/Desktop/DS2/training.ipynb#ch0000016?line=11'>12</a>\u001b[0m loss \u001b[39m=\u001b[39m criterion(pred, tag)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nzams/Desktop/DS2/training.ipynb#ch0000016?line=12'>13</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32mc:\\Users\\nzams\\Desktop\\DS2\\training.ipynb Cell 9\u001b[0m in \u001b[0;36mCNN_LSTM.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nzams/Desktop/DS2/training.ipynb#ch0000016?line=19'>20</a>\u001b[0m x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msqueeze(x)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nzams/Desktop/DS2/training.ipynb#ch0000016?line=20'>21</a>\u001b[0m x, (h_n, c_n) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlstm(x, (torch\u001b[39m.\u001b[39mzeros(\u001b[39m1\u001b[39m, \u001b[39m40\u001b[39m, \u001b[39m200\u001b[39m), torch\u001b[39m.\u001b[39mzeros(\u001b[39m1\u001b[39m, \u001b[39m40\u001b[39m, \u001b[39m200\u001b[39m)))\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/nzams/Desktop/DS2/training.ipynb#ch0000016?line=21'>22</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv2(x)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nzams/Desktop/DS2/training.ipynb#ch0000016?line=22'>23</a>\u001b[0m x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mflatten(x)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nzams/Desktop/DS2/training.ipynb#ch0000016?line=23'>24</a>\u001b[0m x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(x)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\conv.py:457\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    456\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 457\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\conv.py:453\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    449\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    450\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[0;32m    451\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[0;32m    452\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[1;32m--> 453\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[0;32m    454\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Given groups=1, weight of size [5, 15, 40, 200], expected input[1, 7, 40, 200] to have 15 channels, but got 7 channels instead"
     ]
    }
   ],
   "source": [
    "fit_model(CNN_LSTM)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
