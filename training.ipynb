{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "device = T.device(\"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "appa_hours = pd.read_csv(\"exports/appa_hr_crop_withCreated.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "appa_hours = appa_hours[['ZnOR_1', 'ZnOR_2', 'LaFeO3_1', 'LaFeO3_2', 'WO3_1', 'WO3_2',\n",
    "       'ZnOR_heatR_1', 'ZnOR_heatR_2', 'LaFeO3_heatR_1', 'LaFeO3_heatR_2',\n",
    "       'WO3_heatR_1', 'WO3_heatR_2', 'ZnOR_heatV_1', 'ZnOR_heatV_2',\n",
    "       'LaFeO3_heatV_1', 'LaFeO3_heatV_2', 'WO3_heatV_1', 'WO3_heatV_2',\n",
    "       'Temperature', 'Relative_Humidity', 'Pressure', 'VOC',\n",
    "       'ZnOR_1_TimeSinceCreated', 'ZnOR_2_TimeSinceCreated',\n",
    "       'LaFeO3_1_TimeSinceCreated', 'LaFeO3_2_TimeSinceCreated',\n",
    "       'WO3_1_TimeSinceCreated', 'WO3_2_TimeSinceCreated', 'NO2', 'SO2', 'O3', 'CO']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 749,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error,median_absolute_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ZnOR_1', 'ZnOR_2', 'LaFeO3_1', 'LaFeO3_2', 'WO3_1', 'WO3_2',\n",
       "       'ZnOR_heatR_1', 'ZnOR_heatR_2', 'LaFeO3_heatR_1', 'LaFeO3_heatR_2',\n",
       "       'WO3_heatR_1', 'WO3_heatR_2', 'ZnOR_heatV_1', 'ZnOR_heatV_2',\n",
       "       'LaFeO3_heatV_1', 'LaFeO3_heatV_2', 'WO3_heatV_1', 'WO3_heatV_2',\n",
       "       'Temperature', 'Relative_Humidity', 'Pressure', 'VOC',\n",
       "       'ZnOR_1_TimeSinceCreated', 'ZnOR_2_TimeSinceCreated',\n",
       "       'LaFeO3_1_TimeSinceCreated', 'LaFeO3_2_TimeSinceCreated',\n",
       "       'WO3_1_TimeSinceCreated', 'WO3_2_TimeSinceCreated'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 595,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "appa_hours.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['ZnOR_1', 'ZnOR_2', 'LaFeO3_1', 'LaFeO3_2', 'WO3_1', 'WO3_2',\n",
    "       'ZnOR_heatR_1', 'ZnOR_heatR_2', 'LaFeO3_heatR_1', 'LaFeO3_heatR_2',\n",
    "       'WO3_heatR_1', 'WO3_heatR_2', 'ZnOR_heatV_1', 'ZnOR_heatV_2',\n",
    "       'LaFeO3_heatV_1', 'LaFeO3_heatV_2', 'WO3_heatV_1', 'WO3_heatV_2',\n",
    "       'Temperature', 'Relative_Humidity', 'Pressure', 'VOC',\n",
    "       'ZnOR_1_TimeSinceCreated', 'ZnOR_2_TimeSinceCreated',\n",
    "       'LaFeO3_1_TimeSinceCreated', 'LaFeO3_2_TimeSinceCreated',\n",
    "       'WO3_1_TimeSinceCreated', 'WO3_2_TimeSinceCreated']\n",
    "outs = ['NO2', 'O3', 'CO']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 756,
   "metadata": {},
   "outputs": [],
   "source": [
    "vsplit = round(len(appa_hours) * 0.2)\n",
    "\n",
    "X_train = appa_hours.iloc[vsplit:][cols]\n",
    "X_test = appa_hours.iloc[:vsplit][cols]\n",
    "\n",
    "Y_train = appa_hours.iloc[vsplit:][outs]\n",
    "Y_test = appa_hours.iloc[:vsplit][outs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 752,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gl/2h8nn4ps031g1jysgll17wz00000gn/T/ipykernel_13826/1006863496.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  model.fit(X_train, Y_train)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor()"
      ]
     },
     "execution_count": 752,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestRegressor()\n",
    "model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 754,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "Median Error: 10.86 \n",
      " Mean error: 12.902733576642337\n"
     ]
    }
   ],
   "source": [
    "Y_test_pred_r = model.predict(X_test)\n",
    "\n",
    "print(\"Random Forest\")\n",
    "print(f\"Median Error: {median_absolute_error(Y_test, Y_test_pred_r)} \\n Mean error: {mean_absolute_error(Y_test, Y_test_pred_r)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Time', 'ZnOR_1', 'ZnOR_2', 'LaFeO3_1', 'LaFeO3_2', 'WO3_1', 'WO3_2',\n",
       "       'ZnOR_heatR_1', 'ZnOR_heatR_2', 'LaFeO3_heatR_1', 'LaFeO3_heatR_2',\n",
       "       'WO3_heatR_1', 'WO3_heatR_2', 'ZnOR_heatV_1', 'ZnOR_heatV_2',\n",
       "       'LaFeO3_heatV_1', 'LaFeO3_heatV_2', 'WO3_heatV_1', 'WO3_heatV_2',\n",
       "       'Temperature', 'Relative_Humidity', 'Pressure', 'VOC', 'PM10', 'NO2',\n",
       "       'SO2', 'O3', 'CO', 'ZnOR_1_TimeSinceCreated', 'ZnOR_2_TimeSinceCreated',\n",
       "       'LaFeO3_1_TimeSinceCreated', 'LaFeO3_2_TimeSinceCreated',\n",
       "       'WO3_1_TimeSinceCreated', 'WO3_2_TimeSinceCreated'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "appa_hours.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(['Time', 'ZnOR_1', 'ZnOR_2', 'LaFeO3_1', 'LaFeO3_2', 'WO3_1', 'WO3_2',\n",
    "       'ZnOR_heatR_1', 'ZnOR_heatR_2', 'LaFeO3_heatR_1', 'LaFeO3_heatR_2',\n",
    "       'WO3_heatR_1', 'WO3_heatR_2', 'ZnOR_heatV_1', 'ZnOR_heatV_2',\n",
    "       'LaFeO3_heatV_1', 'LaFeO3_heatV_2', 'WO3_heatV_1', 'WO3_heatV_2',\n",
    "       'Temperature', 'Relative_Humidity', 'Pressure', 'VOC','ZnOR_1_TimeSinceCreated', 'ZnOR_2_TimeSinceCreated',\n",
    "       'LaFeO3_1_TimeSinceCreated', 'LaFeO3_2_TimeSinceCreated',\n",
    "       'WO3_1_TimeSinceCreated', 'WO3_2_TimeSinceCreated'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13678, 24, 28)"
      ]
     },
     "execution_count": 569,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BasicNet(\n",
      "  (conv1): Conv2d(1, 20, kernel_size=(4, 4), stride=(1, 1))\n",
      "  (conv2): Conv2d(20, 3, kernel_size=(4, 4), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=1188, out_features=200, bias=True)\n",
      "  (fc2): Linear(in_features=200, out_features=150, bias=True)\n",
      "  (fc3): Linear(in_features=150, out_features=50, bias=True)\n",
      "  (fc4): Linear(in_features=50, out_features=3, bias=True)\n",
      "  (dropout1): Dropout(p=0.25, inplace=False)\n",
      "  (dropout2): Dropout(p=0.5, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class BasicNet(nn.Module):\n",
    "    def __init__(self, in_channel):\n",
    "        super(BasicNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=in_channel, out_channels=20, kernel_size=(4,4))\n",
    "\n",
    "        self.conv2 = nn.Conv2d(in_channels=20, out_channels=3, kernel_size=(4, 4))\n",
    "\n",
    "        self.fc1 = nn.Linear(1188, 200)\n",
    "        self.fc2 = nn.Linear(200, 150)\n",
    "        self.fc3 = nn.Linear(150, 50)\n",
    "        self.fc4 = nn.Linear(50, 3)\n",
    "\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc1(torch.flatten(x))\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "basic_model = BasicNet(1)\n",
    "print(basic_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0022,  0.1585, -0.0574], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 667,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_model(torch.tensor(X[0]).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = appa_hours[['ZnOR_1', 'ZnOR_2', 'LaFeO3_1', 'LaFeO3_2', 'WO3_1', 'WO3_2',\n",
    "       'ZnOR_heatR_1', 'ZnOR_heatR_2', 'LaFeO3_heatR_1', 'LaFeO3_heatR_2',\n",
    "       'WO3_heatR_1', 'WO3_heatR_2', 'ZnOR_heatV_1', 'ZnOR_heatV_2',\n",
    "       'LaFeO3_heatV_1', 'LaFeO3_heatV_2', 'WO3_heatV_1', 'WO3_heatV_2',\n",
    "       'Temperature', 'Relative_Humidity', 'Pressure', 'VOC',\n",
    "       'ZnOR_1_TimeSinceCreated', 'ZnOR_2_TimeSinceCreated',\n",
    "       'LaFeO3_1_TimeSinceCreated', 'LaFeO3_2_TimeSinceCreated',\n",
    "       'WO3_1_TimeSinceCreated', 'WO3_2_TimeSinceCreated']].to_numpy()\n",
    "Y = appa_hours[['NO2', 'O3', 'CO']].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalerX = preprocessing.StandardScaler().fit(X)\n",
    "X = scalerX.transform(X)\n",
    "scalerY = preprocessing.StandardScaler().fit(Y)\n",
    "Y = scalerY.transform(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((13678, 1, 24, 28), (13701, 3))"
      ]
     },
     "execution_count": 584,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.lib.stride_tricks.sliding_window_view(X, (24,28))\n",
    "Y = Y[X.shape[1]-1:]\n",
    "(X.shape,Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for i in range(len(X)):\n",
    "    data.append([X[i], Y[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [],
   "source": [
    "vsplit = round(len(data) * 0.2)\n",
    "\n",
    "train_dl = DataLoader(data[vsplit:], batch_size=32, shuffle=True)\n",
    "test_dl = DataLoader(data[:vsplit], batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_dl, model):\n",
    "    global bm\n",
    "    best_loss = float(\"inf\")\n",
    "    # define the optimization\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.SGD(basic_model.parameters(), lr=0.01, momentum=0.9)\n",
    "    # enumerate epochs\n",
    "    for epoch in range(100):\n",
    "        for i, (inputs, targets) in enumerate(train_dl):\n",
    "            # clear the gradients\n",
    "            optimizer.zero_grad()\n",
    "            # compute the model output\n",
    "            for i, inp in enumerate(inputs):\n",
    "                yhat = model(inp.float())\n",
    "                # calculate loss\n",
    "                loss = criterion(yhat, targets[i].float())\n",
    "                # credit assignment\n",
    "                loss.backward()\n",
    "            # update model weights\n",
    "            optimizer.step()\n",
    "        if best_loss > loss:\n",
    "            bm = copy.deepcopy(model)\n",
    "            best_loss = loss\n",
    "        print(f\"epoch {epoch} done, loss {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(test_dl, model):\n",
    "    predictions, actuals = list(), list()\n",
    "    for i, (inputs, targets) in enumerate(test_dl):\n",
    "        # evaluate the model on the test set\n",
    "        for i, inp in enumerate(inputs):\n",
    "            yhat = model(inp.float())\n",
    "            # retrieve numpy array\n",
    "            yhat = yhat.detach().numpy()\n",
    "            actual = targets[i].numpy()\n",
    "            # store\n",
    "            predictions.append(yhat)\n",
    "            actuals.append(actual)\n",
    "    predictions, actuals = np.vstack(predictions), np.vstack(actuals)\n",
    "    # calculate accuracy\n",
    "    acc = (actuals, predictions)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 done, loss 0.21166719496250153\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/neelredkar/Documents/Git/webvalleyTests/training.ipynb Cell 25\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/neelredkar/Documents/Git/webvalleyTests/training.ipynb#ch0000045?line=0'>1</a>\u001b[0m train_model(train_dl, basic_model)\n",
      "\u001b[1;32m/Users/neelredkar/Documents/Git/webvalleyTests/training.ipynb Cell 25\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(train_dl, model)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/neelredkar/Documents/Git/webvalleyTests/training.ipynb#ch0000045?line=15'>16</a>\u001b[0m     loss \u001b[39m=\u001b[39m criterion(yhat, targets[i]\u001b[39m.\u001b[39mfloat())\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/neelredkar/Documents/Git/webvalleyTests/training.ipynb#ch0000045?line=16'>17</a>\u001b[0m     \u001b[39m# credit assignment\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/neelredkar/Documents/Git/webvalleyTests/training.ipynb#ch0000045?line=17'>18</a>\u001b[0m     loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/neelredkar/Documents/Git/webvalleyTests/training.ipynb#ch0000045?line=18'>19</a>\u001b[0m \u001b[39m# update model weights\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/neelredkar/Documents/Git/webvalleyTests/training.ipynb#ch0000045?line=19'>20</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/torch/_tensor.py:484\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    474\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    475\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    476\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    477\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    482\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    483\u001b[0m     )\n\u001b[0;32m--> 484\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    485\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    486\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/torch/autograd/__init__.py:191\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    186\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    188\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    189\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    190\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 191\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    192\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    193\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_model(train_dl, basic_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0576, -0.0222, -0.0243], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 642,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_model(torch.rand((1,24,28)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.764513163195716"
      ]
     },
     "execution_count": 630,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, median_absolute_error, mean_absolute_error\n",
    "evals = evaluate_model(test_dl, basic_model)\n",
    "\n",
    "median_absolute_error(scalerY.inverse_transform(evals[1]),  scalerY.inverse_transform(evals[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.05760721, -0.02216033, -0.02431159],\n",
       "       [-0.05760721, -0.02216033, -0.02431159],\n",
       "       [-0.05760721, -0.02216033, -0.02431159],\n",
       "       ...,\n",
       "       [-0.05760721, -0.02216033, -0.02431159],\n",
       "       [-0.05760721, -0.02216033, -0.02431159],\n",
       "       [-0.05760721, -0.02216033, -0.02431159]], dtype=float32)"
      ]
     },
     "execution_count": 631,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evals[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_windows(array, clearing_time_index, max_time, sub_window_size):\n",
    "    examples = []\n",
    "    start = clearing_time_index + 1 - sub_window_size + 1\n",
    "    \n",
    "    for i in range(max_time+1):\n",
    "        example = array[start+i:start+sub_window_size+i]\n",
    "        examples.append(np.expand_dims(example, 0))\n",
    "    \n",
    "    return np.vstack(examples)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ac2eaa0ea0ebeafcc7822e65e46aa9d4f966f30b695406963e145ea4a91cd4fc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
