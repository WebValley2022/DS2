{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import time\n",
    "import math\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "from matplotlib import pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')\n",
    "\n",
    "appa1 = pd.read_csv(\"noam_exports/appa1.csv\")\n",
    "appa1 = appa1.drop(columns='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN-LSTM Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN_LSTM(\n",
      "  (conv): Conv2d(1, 40, kernel_size=(4, 37), stride=(1, 1))\n",
      "  (lstm): LSTM(21, 200)\n",
      "  (fc1): Linear(in_features=200, out_features=150, bias=True)\n",
      "  (fc2): Linear(in_features=150, out_features=50, bias=True)\n",
      "  (fc3): Linear(in_features=50, out_features=3, bias=True)\n",
      "  (dropout1): Dropout(p=0.03, inplace=False)\n",
      "  (dropout2): Dropout(p=0.1, inplace=False)\n",
      "  (dropout3): Dropout(p=0.1, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torch import max_pool2d\n",
    "\n",
    "\n",
    "class CNN_LSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_LSTM, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels=1, out_channels=40, kernel_size=(4, 37))\n",
    "        self.lstm = nn.LSTM(21, 200)\n",
    "        self.fc1 = nn.Linear(200, 150)\n",
    "        self.fc2 = nn.Linear(150, 50)\n",
    "        self.fc3 = nn.Linear(50,3)\n",
    "        self.dropout1 = nn.Dropout(0.03)\n",
    "        self.dropout2 = nn.Dropout(0.1)\n",
    "        self.dropout3 = nn.Dropout(0.1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = F.relu(x)\n",
    "        x = torch.squeeze(x)\n",
    "        x, (h_n, c_n) = self.lstm(x, (torch.zeros(1, 40, 200), torch.zeros(1, 40, 200)))\n",
    "        x = F.relu(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.dropout3(x)\n",
    "        print(x.shape)\n",
    "        return x\n",
    "\n",
    "CNN_LSTM = CNN_LSTM()\n",
    "print(CNN_LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = appa1[[\n",
    "       'ZnOR_1', 'ZnOR_2',\n",
    "       'LaFeO3_1', 'LaFeO3_2',\n",
    "       'WO3_1', 'WO3_2',\n",
    "       'ZnOR_1_heatR', 'ZnOR_2_heatR',\n",
    "       'LaFeO3_1_heatR', 'LaFeO3_2_heatR',\n",
    "       'WO3_1_heatR', 'WO3_2_heatR',\n",
    "       'ZnOR_1_heatV', 'ZnOR_2_heatV',\n",
    "       'LaFeO3_1_heatV', 'LaFeO3_2_heatV',\n",
    "       'WO3_1_heatV', 'WO3_2_heatV',\n",
    "       'Temperature', 'Relative_Humidity', 'Pressure', 'VOC',\n",
    "       'ZnOR_1_Age', 'ZnOR_2_Age',\n",
    "       'LaFeO3_1_Age', 'LaFeO3_2_Age',\n",
    "       'WO3_1_Age', 'WO3_2_Age',\n",
    "       'sin_hour', 'cos_hour',\n",
    "       'sin_weekday', 'cos_weekday',\n",
    "       'sin_month', 'cos_month',\n",
    "       'sin_ordate', 'cos_ordate',\n",
    "       'year'\n",
    "    ]].to_numpy()\n",
    "Y = appa1[['NO2', 'O3', 'CO']].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((13678, 1, 24, 37), (13678, 3))"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.lib.stride_tricks.sliding_window_view(X, (24, 37))\n",
    "Y = Y[X.shape[2] - 1 :]\n",
    "(X.shape, Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(list(zip(X,Y)), test_size=0.2)\n",
    "\n",
    "train_dl = DataLoader(train, batch_size=15, shuffle=True)\n",
    "test_dl = DataLoader(test, batch_size=15, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(model):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = CNN_LSTM\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "    for epoch in range(1, 11):\n",
    "        train_loss = 0\n",
    "        for features, tag in tqdm(train_dl):\n",
    "            optimizer.zero_grad()\n",
    "            pred = model(torch.tensor(features).float())\n",
    "            loss = criterion(pred, tag)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        print(f'EPOCH: {epoch}; TRAIN LOSS: {train_loss}')\n",
    "        test_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for features, tag in tqdm(test_dl):\n",
    "                pred = model(tag)\n",
    "                loss = criterion(pred, tag)\n",
    "                test_loss += loss.item()\n",
    "                print(f'EPOCH: {epoch}; TEST LOSS: {test_loss}')\n",
    "\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/730 [00:00<?, ?it/s]C:\\Users\\nzams\\AppData\\Local\\Temp\\ipykernel_12912\\1177280461.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pred = model(torch.tensor(features).float())\n",
      "C:\\Users\\nzams\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\loss.py:530: UserWarning: Using a target size (torch.Size([15, 3])) that is different to the input size (torch.Size([15, 40, 3])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "  0%|          | 0/730 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([15, 40, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (40) must match the size of tensor b (15) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\nzams\\Desktop\\DS2\\training.ipynb Cell 9\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/nzams/Desktop/DS2/training.ipynb#ch0000016?line=0'>1</a>\u001b[0m fit_model(CNN_LSTM)\n",
      "\u001b[1;32mc:\\Users\\nzams\\Desktop\\DS2\\training.ipynb Cell 9\u001b[0m in \u001b[0;36mfit_model\u001b[1;34m(model)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nzams/Desktop/DS2/training.ipynb#ch0000016?line=8'>9</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nzams/Desktop/DS2/training.ipynb#ch0000016?line=9'>10</a>\u001b[0m pred \u001b[39m=\u001b[39m model(torch\u001b[39m.\u001b[39mtensor(features)\u001b[39m.\u001b[39mfloat())\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/nzams/Desktop/DS2/training.ipynb#ch0000016?line=10'>11</a>\u001b[0m loss \u001b[39m=\u001b[39m criterion(pred, tag)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nzams/Desktop/DS2/training.ipynb#ch0000016?line=11'>12</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nzams/Desktop/DS2/training.ipynb#ch0000016?line=12'>13</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\loss.py:530\u001b[0m, in \u001b[0;36mMSELoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m    529\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor, target: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 530\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mmse_loss(\u001b[39minput\u001b[39;49m, target, reduction\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreduction)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\functional.py:3279\u001b[0m, in \u001b[0;36mmse_loss\u001b[1;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[0;32m   3276\u001b[0m \u001b[39mif\u001b[39;00m size_average \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m reduce \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   3277\u001b[0m     reduction \u001b[39m=\u001b[39m _Reduction\u001b[39m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[1;32m-> 3279\u001b[0m expanded_input, expanded_target \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mbroadcast_tensors(\u001b[39minput\u001b[39;49m, target)\n\u001b[0;32m   3280\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39m_C\u001b[39m.\u001b[39m_nn\u001b[39m.\u001b[39mmse_loss(expanded_input, expanded_target, _Reduction\u001b[39m.\u001b[39mget_enum(reduction))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\functional.py:73\u001b[0m, in \u001b[0;36mbroadcast_tensors\u001b[1;34m(*tensors)\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function(tensors):\n\u001b[0;32m     72\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(broadcast_tensors, tensors, \u001b[39m*\u001b[39mtensors)\n\u001b[1;32m---> 73\u001b[0m \u001b[39mreturn\u001b[39;00m _VF\u001b[39m.\u001b[39;49mbroadcast_tensors(tensors)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (40) must match the size of tensor b (15) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "fit_model(CNN_LSTM)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
