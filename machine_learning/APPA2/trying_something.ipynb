{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "from sklearn.model_selection import RepeatedKFold, cross_validate\n",
    "from sklearn.metrics import mean_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Read the file in which the values are saved\n",
    "appa2 = pd.read_csv(\"../../exports/appa2_shrinked.csv\")\n",
    "appa2 = appa2.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting all the values we need to train and test the model\n",
    "appa2 = appa2[[\n",
    "    'LaFeO3_1', 'LaFeO3_2', \n",
    "    'STN_1', 'STN_2', \n",
    "    'LaFeO3_1_heatR', 'LaFeO3_2_heatR',\n",
    "    'STN_1_heatR', 'STN_2_heatR', \n",
    "    \"LaFeO3_1_Age\", \"LaFeO3_2_Age\",\n",
    "    \"STN_1_Age\",\"STN_2_Age\",\n",
    "    'Temperature', 'Relative_Humidity', 'Pressure', 'VOC', \n",
    "    'Wind_Speed', \n",
    "    'PM10', 'CO', 'NO2'\n",
    "]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Select the features\n",
    "cols = [\n",
    "    'LaFeO3_1', 'LaFeO3_2', \n",
    "    'STN_1', 'STN_2', \n",
    "    'LaFeO3_1_heatR', 'LaFeO3_2_heatR',\n",
    "    'STN_1_heatR', 'STN_2_heatR', \n",
    "    \"LaFeO3_1_Age\", \"LaFeO3_2_Age\",\n",
    "    \"STN_1_Age\",\"STN_2_Age\",\n",
    "    'Temperature', 'Relative_Humidity', 'Pressure', 'VOC', \n",
    "    'Wind_Speed'\n",
    "]\n",
    "\n",
    "# Select the target\n",
    "outs = ['PM10', 'CO', 'NO2']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# # Split the values in training and test\n",
    "# vsplit = round(len(appa2) * 0.2)\n",
    "\n",
    "# X_train = appa2.iloc[vsplit:][cols]\n",
    "# X_test = appa2.iloc[:vsplit][cols]\n",
    "\n",
    "# Y_train = appa2.iloc[vsplit:][outs]\n",
    "# Y_test = appa2.iloc[:vsplit][outs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['LaFeO3_1', 'LaFeO3_2', 'STN_1', 'STN_2', 'LaFeO3_1_heatR',\n",
       "        'LaFeO3_2_heatR', 'STN_1_heatR', 'STN_2_heatR', 'LaFeO3_1_Age',\n",
       "        'LaFeO3_2_Age', 'STN_1_Age', 'STN_2_Age', 'Temperature',\n",
       "        'Relative_Humidity', 'Pressure', 'VOC', 'Wind_Speed'],\n",
       "       dtype='object'),\n",
       " Index(['PM10', 'CO', 'NO2'], dtype='object'))"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = appa2[cols]\n",
    "target= appa2[outs]\n",
    "\n",
    "features.columns, target.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = RepeatedKFold(n_splits = 10, n_repeats = 1)\n",
    "\n",
    "for train_index, test_index in kf.split(features.values):\n",
    "    X_train, X_test = features[train_index], features[test_index]\n",
    "    Y_train, Y_test = target[train_index], target[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(features, target, test_size=0.2, random_state=42, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_X_train, working_X_test, working_Y_train, working_Y_test = X_train, X_test, Y_train, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start= 1000, stop= 2000, num=10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num=11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [4, 5, 6]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [2, 3, 6]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Choose the type of model\n",
    "model = RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ris = cross_validate(model, features, target, cv = 10, n_jobs= -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.02287442, -0.20037839, -0.05824684, -0.51274001, -0.79642106,\n",
       "        0.02923268, -0.64532628, -0.5165638 , -0.35324025, -0.67153109])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ris.keys()\n",
    "\n",
    "model_ris[\"test_score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Perform the RandomForestRegression with a Random Search on hyperparameters\n",
    "rf_random = RandomizedSearchCV(estimator=model, param_distributions=random_grid, n_iter=100, cv=3, verbose=2,\n",
    "                               random_state=42, n_jobs=-1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Create a Dataframe with the results of the model and then saving them into a .csv file\n",
    "ris = pd.DataFrame(rf_random.cv_results_)\n",
    "ris.to_csv('results/results_weather2_shrinked_shuffle(1).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Save the model itself in a .sav file\n",
    "pickle.dump(rf_random, open('models/model_weather2_shrinked_shuffle(1).sav', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random = pickle.load(open(\"models/model_weather2_shrinked_shuffle(1).sav\", \"rb\"))\n",
    "rf_random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percentage(mean_abs_err, describer):\n",
    "    perc = mean_abs_err / (describer.max() - describer.min())\n",
    "    return perc * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(\"PM10: \" + str(percentage(mean_absolute_error(Y_test.PM10 , rf_random.predict(X_test)[: ,0]), Y_test.PM10) ))\n",
    "print(\"CO: \" + str(percentage(mean_absolute_error(Y_test.CO , rf_random.predict(X_test)[: ,1]), Y_test.CO)))\n",
    "print(\"NO2: \" + str(percentage(mean_absolute_error(Y_test.NO2 , rf_random.predict(X_test)[: ,2]), Y_test.NO2)))\n",
    "print(\"Total: \\n\" + str(mean_absolute_error(Y_test, rf_random.predict(X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random.predict(X_test)[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RSS (Residual Sum of Squares) --> it estimates the variance in the residuals\n",
    "def residual_sum(real, predict):\n",
    "    rss = 0\n",
    "    for index in range(len(real)):\n",
    "        rss += (real[index] - predict[index]) ** 2 \n",
    "    return rss\n",
    "\n",
    "# TSS (Total Sum of Squares) --> the squared differences between the observed dependent variable and its mean\n",
    "def total_sum_square(real):\n",
    "    tss = 0\n",
    "    meanR = real.mean()\n",
    "    for index in range(len(real)):\n",
    "        tss += (real[index] - meanR) ** 2 \n",
    "    return tss\n",
    "\n",
    "# R^2 Coefficient of determination --> Statistical maeasure that represents the proportion of the variance for a dependent variable that's explained by an indipendent variable or variables in a regression model\n",
    "def r_squared(real, predict):\n",
    "    value = residual_sum(real, predict)/total_sum_square(real)\n",
    "    return 1 - value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"PM10: {r2_score(Y_test.PM10, rf_random.predict(X_test)[:, 0])}\" ) \n",
    "print(f\"CO: {r2_score(Y_test.CO, rf_random.predict(X_test)[:, 1])}\")\n",
    "print(f\"NO2: {r2_score(Y_test.NO2, rf_random.predict(X_test)[:, 2])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Hyperparameters Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ris = pd.read_csv(\"results/results_weather2_shrinked_shuffle(1).csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Plot the hyper-parameters in relation of mean test score\n",
    "# Values are plotted through dots. The brighter the dot, the more times that value has been chosen by the models.\n",
    "# On the X axis, the closer the values are to 0 the better they are\n",
    "\n",
    "h_params = ['param_n_estimators', 'param_max_depth', 'param_min_samples_split', 'param_min_samples_leaf', ]\n",
    "fig = plt.figure(figsize=(25, 20))\n",
    "fig.suptitle('Hyper Parameters')\n",
    "outer = gridspec.GridSpec(3, 2, wspace=0.2, hspace=0.2)\n",
    "for index, h_param in enumerate(h_params):\n",
    "    ax = plt.Subplot(fig, outer[index])\n",
    "    ax.scatter(ris['mean_test_score'], ris[h_param], color='red', alpha=0.4, )\n",
    "    ax.set_ylabel(h_param)\n",
    "    ax.set_xlabel('mean_test_score')\n",
    "    # ax.set_ylim(105, 110)\n",
    "    fig.add_subplot(ax)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot()\n",
    "ax.barh(X_test.columns, rf_random.best_estimator_.feature_importances_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Printing the charts to undersand better our predictions\n",
    "\n",
    "fig,((ax1,ax2), (ax3, ax4)) = plt.subplots(nrows=2, ncols=2, figsize=(20, 20))\n",
    "\n",
    "ax1.scatter(Y_test.PM10, rf_random.predict(X_test)[:, 0], label = \"PM10\")\n",
    "ax2.scatter(Y_test.CO, rf_random.predict(X_test)[:, 1], label = \"CO\")\n",
    "ax3.scatter(Y_test.NO2, rf_random.predict(X_test)[:, 2], label = \"NO2\")\n",
    "\n",
    "ax1.set_xlim(0, 45)\n",
    "ax1.set_ylim(0, 45)\n",
    "ax2.set_xlim(0, 1.5)\n",
    "ax2.set_ylim(0, 1.5)\n",
    "ax3.set_xlim(0.5, 90)\n",
    "ax3.set_ylim(0.5, 90)\n",
    "\n",
    "ax1.set_title('PM10')\n",
    "ax1.set_xlabel('Real data')\n",
    "ax1.set_ylabel('Prediciton')\n",
    "ax2.set_title('CO')\n",
    "ax2.set_xlabel('Real data')\n",
    "ax2.set_ylabel('Prediciton')\n",
    "ax3.set_title('NO2')\n",
    "ax3.set_xlabel('Real Data')\n",
    "ax3.set_ylabel('Prediction')\n",
    "\n",
    "ax1.legend()\n",
    "ax2.legend()\n",
    "ax3.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gases = Y_test.columns\n",
    "\n",
    "fig = plt.figure(figsize=(15, 15))\n",
    "fig.suptitle('Gases')\n",
    "outer = gridspec.GridSpec(2, 2, wspace=0.2, hspace=0.2)\n",
    "for index, gas in enumerate(gases):\n",
    "    ax = plt.Subplot(fig, outer[index])\n",
    "    ax.scatter(Y_test[gas], rf_random.predict(X_test)[:,index], marker=\".\", alpha=0.2, label=gas)\n",
    "    ax.set_xlabel(f\"Real\")\n",
    "    ax.set_ylabel(f\"Predict\")\n",
    "    ax.set_xlim(0, Y_test[gas].max()*9/8)\n",
    "    ax.set_ylim(0, Y_test[gas].max()*9/8)\n",
    "    ax.plot([-100, Y_test[gas].max()*10], [-100,  Y_test[gas].max()*10], c=\"k\", alpha=1)\n",
    "    ax.legend()\n",
    "    fig.add_subplot(ax)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "appa2.CO.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "appa2.CO.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train.CO.value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c347c8f9a7ef94e4c9e03b4513be7835ed18f45b99a2a817fb579f408b867b16"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
